{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33b23e-ce96-45d8-9d77-e2824b8494e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scala.util.Properties.versionString\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5b8e5-00ca-48d0-89ed-9076697a8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.3.2`\n",
    "import org.apache.spark.sql.SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6a171-c8cc-42ea-8967-38f60da09bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"Retail Data Analytics\")\n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate()\n",
    "\n",
    "// Import implicits for DataFrame operations\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb4178-d556-4b74-8b85-cea30672ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = spark.read\n",
    "  .option(\"header\", \"true\")             // First row contains column names\n",
    "  .option(\"inferSchema\", \"true\")        // Automatically infer data types\n",
    "  .option(\"encoding\", \"ISO-8859-1\")     // Correct encoding for special characters\n",
    "  .csv(\"online_retail_ii.csv\")          // File path (same directory)\n",
    "\n",
    "df.show(10)                             // Display first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f9f65-b8d3-4efa-8af3-851788fee775",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Display the first 10 rows of the DataFrame to get an overview of the data\n",
    "df.show(10)\n",
    "\n",
    "// Print the schema to understand the structure and data types of the columns\n",
    "df.printSchema()\n",
    "\n",
    "// Count the total number of rows in the DataFrame\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4ef79-2459-4e5f-846c-2c61d1921735",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove all rows with any null values\n",
    "val df_cleaned = df.na.drop()\n",
    "\n",
    "// Show the first 5 rows of the cleaned DataFrame\n",
    "df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbebb7-4a79-4e65-8396-34771ba96c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove all rows that contain any null (missing) values\n",
    "val df_cleaned = df.na.drop()\n",
    "\n",
    "// Display the first 5 rows of the cleaned DataFrame\n",
    "df_cleaned.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69df8c-e461-437f-9ed4-507580a776af",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Count the total number of rows remaining after removing null values\n",
    "df_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf8dbc-4dd4-4cb3-846f-566fee0ad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Display basic statistics for all numeric columns\n",
    "df_cleaned.describe().show()\n",
    "\n",
    "// Print the schema of the cleaned DataFrame\n",
    "df_cleaned.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce6bd6-943a-4041-8daa-d49ebbe813c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove rows with any null (missing) values\n",
    "val df_cleaned = df\n",
    "  .na.drop()\n",
    "  // Keep only rows where Quantity is greater than 0 (removes returns or errors)\n",
    "  .filter($\"Quantity\" > 0)\n",
    "  // Add a new column \"TotalPrice\" by multiplying Quantity and Price\n",
    "  .withColumn(\"TotalPrice\", $\"Quantity\" * $\"Price\")\n",
    "\n",
    "// Display the first 5 rows showing Quantity, Price, and TotalPrice\n",
    "df_cleaned.select(\"Quantity\", \"Price\", \"TotalPrice\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf43c1-d5c4-4e0f-bc3d-e29d28ac457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Group the data by country and calculate the total sales (sum of TotalPrice)\n",
    "val sales_by_country = df_cleaned\n",
    "  .groupBy(\"Country\")\n",
    "  .agg(sum(\"TotalPrice\").as(\"TotalSales\"))\n",
    "\n",
    "// Display the top 10 countries with the highest total sales, in descending order\n",
    "sales_by_country.orderBy(desc(\"TotalSales\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb3f9b-d27d-40fa-a8b3-4c4686026515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Group the data by product description and calculate total sales for each product\n",
    "val top_products = df_cleaned\n",
    "  .groupBy(\"Description\")\n",
    "  .agg(sum(\"TotalPrice\").as(\"TotalSales\"))\n",
    "\n",
    "// Display the 10 products that generated the most revenue\n",
    "top_products.orderBy(desc(\"TotalSales\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931d239-1429-4069-b692-259c9a39229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Group the data by product description and calculate the total quantity sold for each product\n",
    "val top_quantity_products = df_cleaned\n",
    "  .groupBy(\"Description\")\n",
    "  .agg(sum(\"Quantity\").as(\"TotalQuantity\"))\n",
    "\n",
    "// Display the 10 products that were sold in the highest quantity\n",
    "top_quantity_products.orderBy(desc(\"TotalQuantity\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4513a16-b863-49e9-aced-c648878ee91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Add a new column \"Month\" by extracting the month number from the InvoiceDate column\n",
    "val df_with_month = df_cleaned.withColumn(\"Month\", month(col(\"InvoiceDate\")))\n",
    "\n",
    "// Group the data by month and calculate total sales for each month\n",
    "val monthly_sales = df_with_month\n",
    "  .groupBy(\"Month\")\n",
    "  .agg(sum(\"TotalPrice\").as(\"MonthlySales\"))\n",
    "\n",
    "// Display the total sales for each month in chronological order\n",
    "monthly_sales.orderBy(\"Month\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
